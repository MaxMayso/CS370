# CS370
Developed and trained an AI model inside of a pirate treasure hunting game

**Pirate Intelligent Agent Project**

In this project, I worked on creating a pirate intelligent agent that uses reinforcement learning to find treasure before a human player does. The challenge was to teach the pirate to navigate through a maze by itself. I was
given some starter code, like TreasureMaze.py and GameExperience.py, which set up the maze and handled some of the behind-the-scenes tasks. My job was to fill in the gaps—specifically writing the deep Q-learning algorithm to
help the pirate agent learn from its mistakes and get better at finding the treasure over time.

I built the training loop that allows the agent to play the game over and over, figuring out the best path by adjusting its actions based on the rewards (when it does well) and penalties (when it doesn't). The agent
gradually learns to make better choices as it repeats the game.

**Reflection**

Throughout this course, I’ve learned how computer scientists tackle problems—especially when it comes to AI and machine learning. Basically, computer scientists are like problem-solving ninjas. We figure out ways to build
smart systems and algorithms that can do things better and faster than humans, which can be pretty important for things like automation, healthcare, and even gaming.

When I approach a problem, I like to break it down into smaller chunks and figure out the best way to solve each piece. I usually start with the first logical error that appears in the compile report. I think about what I
need to achieve, check out what solutions already exist, and then piece it all together. In this project, that meant understanding how reinforcement learning works, choosing deep Q-learning for the agent, and coding it in a
way that makes the pirate find treasure as quickly as possible.

I also get that being a computer scientist means thinking about the bigger picture, like the ethical side of things. It's important to make sure the stuff we' build is fair, safe, and doesnt hurt anyone. That means
considering things like user privacy, avoiding bias in the algorithms, and making sure that the technology benefits society instead of causing problems. In short, I’ve learned that my role isn’t just about solving cool 
problems—it’s about doing it responsibly.

Thank you, 

Max
